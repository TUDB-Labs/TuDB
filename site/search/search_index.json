{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"TuDB \u00b6 What is TuDB? \u00b6 TuDB is a cloud native graph database. TuDB aims to support Hybrid Transactional and Analytical Processing (HTAP) workloads. It is compatible with Cypher and features horizontal scalability, strong consistency, and high availability. TuDB aims to provide a unified graph process interface for constructing and managing graphs on different key-value storage engines, such as RocksDB, HBase, and TiKV. Quick Start \u00b6 Installation \u00b6 You can install TuDB by following these steps: Download or clone the repo locally. Install Maven . Run the following to build TuDB binary: mvn clean compile install Examples \u00b6 Below is an example to start the server and client locally and interact with the database via Cypher queries. For more examples, please check out the examples folder . import org . apache . commons . io . FileUtils import org . grapheco . lynx . types . structural .{ LynxNode , LynxRelationship } import org . grapheco . tudb .{ TuDBServer , TuDBServerContext } import org . grapheco . tudb . client . TuDBClient import org . grapheco . tudb . test . TestUtils import java . io . File object CypherExample { val port = 7600 var server : TuDBServer = _ var client : TuDBClient = _ def main ( args : Array [ String ]): Unit = { val dbPath : String = s\" ${ TestUtils . getModuleRootPath } /testSpace/testBase\" server = startServer ( dbPath , port ) startClient () createNode () queryNode () createRelation () queryRelation () stopClient () shutdownServer () } def startServer ( dbPath : String , port : Int , indexUrl : String = \"tudb://index?type=dummy\" ): TuDBServer = { FileUtils . deleteDirectory ( new File ( dbPath )) val serverContext = new TuDBServerContext () serverContext . setPort ( port ) serverContext . setDataPath ( dbPath ) serverContext . setIndexUri ( indexUrl ) val server = new TuDBServer ( serverContext ) new Thread ( new Runnable { override def run (): Unit = server . start () }). start () server } def shutdownServer () = server . shutdown () def startClient (): Unit = { client = new TuDBClient ( \"127.0.0.1\" , port ) } def stopClient () = client . shutdown () def createNode (): Unit = { client . query ( \"create (n:DataBase{name:'TuDB'})\" ) client . query ( \"create (n: Company{name:'TUDB'})\" ) } def queryNode (): Unit = { val res = client . query ( \"match (n) return n\" ) println () println ( \"Query Node result: \" , res ) println () } def createRelation (): Unit = { client . query ( \"\"\" |match (n:DataBase{name:'TuDB'}) |match (c: Company{name:'TUDB'}) |create (n)-[r: belongTo{year: 2022}]->(c) |\"\"\" . stripMargin ) } def queryRelation (): Unit = { val res = client . query ( \"match (n)-[r: belongTo]->(m) return n,r,m\" ) println () println ( \"Query Relation Result: \" , res ) } } Development \u00b6 You can run all the tests via the following: mvn clean install test You can start a database instance locally via ./bin/start or start an interactive shell via ./bin/cypher . For more details on how to contribute, please check out our contributing guide .","title":"Home"},{"location":"#tudb","text":"","title":"TuDB"},{"location":"#what-is-tudb","text":"TuDB is a cloud native graph database. TuDB aims to support Hybrid Transactional and Analytical Processing (HTAP) workloads. It is compatible with Cypher and features horizontal scalability, strong consistency, and high availability. TuDB aims to provide a unified graph process interface for constructing and managing graphs on different key-value storage engines, such as RocksDB, HBase, and TiKV.","title":"What is TuDB?"},{"location":"#quick-start","text":"","title":"Quick Start"},{"location":"#installation","text":"You can install TuDB by following these steps: Download or clone the repo locally. Install Maven . Run the following to build TuDB binary: mvn clean compile install","title":"Installation"},{"location":"#examples","text":"Below is an example to start the server and client locally and interact with the database via Cypher queries. For more examples, please check out the examples folder . import org . apache . commons . io . FileUtils import org . grapheco . lynx . types . structural .{ LynxNode , LynxRelationship } import org . grapheco . tudb .{ TuDBServer , TuDBServerContext } import org . grapheco . tudb . client . TuDBClient import org . grapheco . tudb . test . TestUtils import java . io . File object CypherExample { val port = 7600 var server : TuDBServer = _ var client : TuDBClient = _ def main ( args : Array [ String ]): Unit = { val dbPath : String = s\" ${ TestUtils . getModuleRootPath } /testSpace/testBase\" server = startServer ( dbPath , port ) startClient () createNode () queryNode () createRelation () queryRelation () stopClient () shutdownServer () } def startServer ( dbPath : String , port : Int , indexUrl : String = \"tudb://index?type=dummy\" ): TuDBServer = { FileUtils . deleteDirectory ( new File ( dbPath )) val serverContext = new TuDBServerContext () serverContext . setPort ( port ) serverContext . setDataPath ( dbPath ) serverContext . setIndexUri ( indexUrl ) val server = new TuDBServer ( serverContext ) new Thread ( new Runnable { override def run (): Unit = server . start () }). start () server } def shutdownServer () = server . shutdown () def startClient (): Unit = { client = new TuDBClient ( \"127.0.0.1\" , port ) } def stopClient () = client . shutdown () def createNode (): Unit = { client . query ( \"create (n:DataBase{name:'TuDB'})\" ) client . query ( \"create (n: Company{name:'TUDB'})\" ) } def queryNode (): Unit = { val res = client . query ( \"match (n) return n\" ) println () println ( \"Query Node result: \" , res ) println () } def createRelation (): Unit = { client . query ( \"\"\" |match (n:DataBase{name:'TuDB'}) |match (c: Company{name:'TUDB'}) |create (n)-[r: belongTo{year: 2022}]->(c) |\"\"\" . stripMargin ) } def queryRelation (): Unit = { val res = client . query ( \"match (n)-[r: belongTo]->(m) return n,r,m\" ) println () println ( \"Query Relation Result: \" , res ) } }","title":"Examples"},{"location":"#development","text":"You can run all the tests via the following: mvn clean install test You can start a database instance locally via ./bin/start or start an interactive shell via ./bin/cypher . For more details on how to contribute, please check out our contributing guide .","title":"Development"},{"location":"CONTRIBUTING/","text":"Contributing Guide \u00b6 Welcome to TuDB's contributing guide! Local Setup \u00b6 Prerequisites \u00b6 Please install the following before walking through the rest of this guide: Java 8 Maven Maven Configuration \u00b6 If you are a developer in China, please modify your Maven configurations in ~/.m2/settings.xml to add the Aliyun Maven Central mirror: <settings> <mirrors> <mirror> <id> alimaven </id> <mirrorOf> central </mirrorOf> <name> aliyun maven </name> <url> https://maven.aliyun.com/repository/public/ </url> </mirror> </mirrors> </settings> Testing \u00b6 Run the following command to run the test suite: mvn -B clean install test --file pom.xml . Pre-commit Checks \u00b6 We run several checks before every commit automatically with pre-commit . Install pre-commit to run the required checks when you commit your changes. Once it's installed, run pre-commit install to install the hooks that will be run automatically when you git commit your changes. You can also run it via pre-commit run on your changes or pre-commit run --all to run the checks on all files. If you'd like to uninstall the pre-commit hooks, run pre-commit uninstall . Submit Changes \u00b6 To submit a change, please follow the following steps: 1. Create a fork and push changes to a branch in your fork. 1. Create a pull request from the branch in your fork . Code Style \u00b6 For Python code, We follows PEP 8 with one exception: lines can be up to 100 characters in length, not 79. For Java code, We follows Oracle\u2019s Java code conventions and Scala guidelines below. The latter is preferred. For Scala code, We follows the official Scala style guide and Databricks Scala guide . The latter is preferred. To format Scala code, run ./dev/scalafmt prior to submitting a PR.","title":"Contributing Guide"},{"location":"CONTRIBUTING/#contributing-guide","text":"Welcome to TuDB's contributing guide!","title":"Contributing Guide"},{"location":"CONTRIBUTING/#local-setup","text":"","title":"Local Setup"},{"location":"CONTRIBUTING/#prerequisites","text":"Please install the following before walking through the rest of this guide: Java 8 Maven","title":"Prerequisites"},{"location":"CONTRIBUTING/#maven-configuration","text":"If you are a developer in China, please modify your Maven configurations in ~/.m2/settings.xml to add the Aliyun Maven Central mirror: <settings> <mirrors> <mirror> <id> alimaven </id> <mirrorOf> central </mirrorOf> <name> aliyun maven </name> <url> https://maven.aliyun.com/repository/public/ </url> </mirror> </mirrors> </settings>","title":"Maven Configuration"},{"location":"CONTRIBUTING/#testing","text":"Run the following command to run the test suite: mvn -B clean install test --file pom.xml .","title":"Testing"},{"location":"CONTRIBUTING/#pre-commit-checks","text":"We run several checks before every commit automatically with pre-commit . Install pre-commit to run the required checks when you commit your changes. Once it's installed, run pre-commit install to install the hooks that will be run automatically when you git commit your changes. You can also run it via pre-commit run on your changes or pre-commit run --all to run the checks on all files. If you'd like to uninstall the pre-commit hooks, run pre-commit uninstall .","title":"Pre-commit Checks"},{"location":"CONTRIBUTING/#submit-changes","text":"To submit a change, please follow the following steps: 1. Create a fork and push changes to a branch in your fork. 1. Create a pull request from the branch in your fork .","title":"Submit Changes"},{"location":"CONTRIBUTING/#code-style","text":"For Python code, We follows PEP 8 with one exception: lines can be up to 100 characters in length, not 79. For Java code, We follows Oracle\u2019s Java code conventions and Scala guidelines below. The latter is preferred. For Scala code, We follows the official Scala style guide and Databricks Scala guide . The latter is preferred. To format Scala code, run ./dev/scalafmt prior to submitting a PR.","title":"Code Style"},{"location":"Configuration/","text":"Configuration Guideline \u00b6 TODO","title":"Configuration Guideline"},{"location":"Configuration/#configuration-guideline","text":"TODO","title":"Configuration Guideline"},{"location":"CypherPlusFunctions/","text":"CypherPlus Functions List \u00b6 Standard Cypher \u00b6 Status Function Notes MATCH WHERE CypherPlus Extension \u00b6 Status Function Notes Blob.fromURL() ~:","title":"CypherPlus Functions List"},{"location":"CypherPlusFunctions/#cypherplus-functions-list","text":"","title":"CypherPlus Functions List"},{"location":"CypherPlusFunctions/#standard-cypher","text":"Status Function Notes MATCH WHERE","title":"Standard Cypher"},{"location":"CypherPlusFunctions/#cypherplus-extension","text":"Status Function Notes Blob.fromURL() ~:","title":"CypherPlus Extension"},{"location":"FAQ/","text":"FAQ \u00b6 Questions about the development. \u00b6 Questions about the deployment. \u00b6 Questions about the usage. \u00b6","title":"FAQ"},{"location":"FAQ/#faq","text":"","title":"FAQ"},{"location":"FAQ/#questions-about-the-development","text":"","title":"Questions about the development."},{"location":"FAQ/#questions-about-the-deployment","text":"","title":"Questions about the deployment."},{"location":"FAQ/#questions-about-the-usage","text":"","title":"Questions about the usage."},{"location":"performance-report/","text":"Performance Report \u00b6 Experiment Setup \u00b6 Environment \u00b6 OS: CentOS7 CPU: 26 cores DISK: SSD Mem: 376G JDK-version: 1.8 Scala-version: 2.12.8 Dataset \u00b6 LDBC-SNB Name # Nodes # Relationships SF1 3115527 17236389 SF3 8879918 50728269 SF10 28125740 166346601 Method \u00b6 Node test: choose the first node from each label, then test different API avg time cost. relation test: choose the first end node from each relation type, then test different API avg time cost. Notice: 1. allNodes : test the time cost of scan all node data in db. 2. findInRelations : test the time cost of return the first 10 relations of this node. Performance Report \u00b6 SF1 Performance \u00b6 NodeStoreAPI avg time cost RelationStoreApi avg time cost allNodes 2444 ms findInRelations 486299 us getNodeById 187896 us getRelationById 11987 us nodeSetProperty 961045 us relationSetProperty 202494 us nodeRemoveProperty 773296 us relationRemoveProperty 158453 us deleteNode 226737 us deleteRelation 36684 us addNode 35091 us addRelation 32427 us SF3 Performance \u00b6 NodeStoreAPI avg time cost RelationStoreApi avg time cost allNodes 7145 ms findInRelations 472155 us getNodeById 368505 us getRelationById 15265 us nodeSetProperty 941363 us relationSetProperty 198322 us nodeRemoveProperty 644449 us relationRemoveProperty 171554 us deleteNode 169693 us deleteRelation 33459 us addNode 32525 us addRelation 32301 us SF10 Performance \u00b6 NodeStoreAPI avg time cost RelationStoreApi avg time cost allNodes 23491 ms findInRelations 589703 us getNodeById 272012 us getRelationById 18101 us nodeSetProperty 941371 us relationSetProperty 193019 us nodeRemoveProperty 865621 us relationRemoveProperty 179682 us deleteNode 197920 us deleteRelation 37630 us addNode 34704 us addRelation 36308 us","title":"Performance Report"},{"location":"performance-report/#performance-report","text":"","title":"Performance Report"},{"location":"performance-report/#experiment-setup","text":"","title":"Experiment Setup"},{"location":"performance-report/#environment","text":"OS: CentOS7 CPU: 26 cores DISK: SSD Mem: 376G JDK-version: 1.8 Scala-version: 2.12.8","title":"Environment"},{"location":"performance-report/#dataset","text":"LDBC-SNB Name # Nodes # Relationships SF1 3115527 17236389 SF3 8879918 50728269 SF10 28125740 166346601","title":"Dataset"},{"location":"performance-report/#method","text":"Node test: choose the first node from each label, then test different API avg time cost. relation test: choose the first end node from each relation type, then test different API avg time cost. Notice: 1. allNodes : test the time cost of scan all node data in db. 2. findInRelations : test the time cost of return the first 10 relations of this node.","title":"Method"},{"location":"performance-report/#performance-report_1","text":"","title":"Performance Report"},{"location":"performance-report/#sf1-performance","text":"NodeStoreAPI avg time cost RelationStoreApi avg time cost allNodes 2444 ms findInRelations 486299 us getNodeById 187896 us getRelationById 11987 us nodeSetProperty 961045 us relationSetProperty 202494 us nodeRemoveProperty 773296 us relationRemoveProperty 158453 us deleteNode 226737 us deleteRelation 36684 us addNode 35091 us addRelation 32427 us","title":"SF1 Performance"},{"location":"performance-report/#sf3-performance","text":"NodeStoreAPI avg time cost RelationStoreApi avg time cost allNodes 7145 ms findInRelations 472155 us getNodeById 368505 us getRelationById 15265 us nodeSetProperty 941363 us relationSetProperty 198322 us nodeRemoveProperty 644449 us relationRemoveProperty 171554 us deleteNode 169693 us deleteRelation 33459 us addNode 32525 us addRelation 32301 us","title":"SF3 Performance"},{"location":"performance-report/#sf10-performance","text":"NodeStoreAPI avg time cost RelationStoreApi avg time cost allNodes 23491 ms findInRelations 589703 us getNodeById 272012 us getRelationById 18101 us nodeSetProperty 941371 us relationSetProperty 193019 us nodeRemoveProperty 865621 us relationRemoveProperty 179682 us deleteNode 197920 us deleteRelation 37630 us addNode 34704 us addRelation 36308 us","title":"SF10 Performance"},{"location":"protocol-services-interface-design/","text":"Protocol, Services, and Interfaces Design \u00b6 Protocol Design \u00b6 Object Definitions \u00b6 Below are the main objects in the protocols. Our services are built on these objects. // Element is the basic structure for both Node and Relationship . It 's ID must be unique to its associated Node or Relationship. // An element also maintains a collection of Properties . An element must belong to a graph . message Element { int32 id = 1 ; string name = 2 ; // The graph ID associated with this element . int32 graph_id = 3 ; repeated Property properties = 4 ; } // Property holds a key - value pair that 's associated with an element. message Property { // The element ID associated with this property . int32 element_id = 1 ; string key = 2 ; google . protobuf . Any value = 3 ; } // Graph is a collection of nodes and relationships . message Graph { int32 id = 1 ; string name = 2 ; repeated Node nodes = 3 ; repeated Relationship relationships = 4 ; } // Node extends Element and connects to relationships . message Node { // The following fields are inherited from Element but we write them here explictly since proto3 does not support inheritance . int32 id = 1 string name = 2 ; int32 graph_id = 3 ; // The graph ID associated with this node . repeated Property properties = 4 ; repeated string labels = 5 ; Relationship in_relation = 6 ; Relationship out_relation = 7 ; } // Relationship extends Element and connects two nodes . message Relationship { // The following fields are inherited from Element but we write them here explictly since proto3 does not support inheritance . string id = 1 string name = 2 ; int32 graph_id = 3 ; // The graph ID associated with this relationship . repeated Property properties = 4 ; Node start_node = 5 ; Node end_node = 6 ; // The type of relationship between the two connected nodes . string relationType = 7 ; } Generic Query \u00b6 We support generic query for advanced users to send query directly to the database: The request only contains statement: message GenericQueryRequest { string statement = 1; } The response contains results (e.g. graph objects), message, and exit code: message GenericResponseStatus { string message = 2; int32 exit_code = 3; } message GenericQueryResponse { repeated map<string, google.protobuf.Any> results = 1; GenericResponseStatus status = 2; } The service definition is as follows: service QueryService { rpc Query(GenericQueryRequest) returns (stream GenericQueryResponse) {} } Object-specific Services \u00b6 We support object-specific services such as create/get/delete graphs to provide easy-to-use endpoints to our REST client and high-level SDKs. Let's use graph service as an example: message GraphCreateRequest { Graph graph = 1 ; } ; message GraphCreateResponse { Graph graph = 1 ; GenericResponseStatus status = 2 ; } ; message GraphGetRequest { string name = 1 ; } ; message GraphGetResponse { Graph graph = 1 ; GenericResponseStatus status = 2 ; } ; message GraphListRequest { // TODO : Some filtering options } ; message GraphListResponse { repeated Graph graphs = 1 ; GenericResponseStatus status = 2 ; } ; message GraphDeleteRequest { string name = 1 ; } ; message GraphDeleteResponse { GenericResponseStatus status = 1 ; } ; service GraphService { rpc CreateGraph(GraphCreateRequest) returns GraphCreateResponse { option (google.api.http) = { post : \"/api/v1/graphs/{graph_name}\" body : \"*\" } ; } rpc GetGraph ( GraphGetRequest ) returns GraphGetResponse { option (google.api.http).get = \"/api/v1/graphs/{name } \"; } rpc ListGraphs(GraphListRequest) returns GraphListResponse { option (google.api.http).get = \" / api / v1 / graphs \"; } rpc DeleteGraph(GraphDeleteRequest) returns GraphDeleteResponse { option (google.api.http).get = \" / api / v1 / graphs / { name } \" ; } } Services for other objects are similar. Interfaces \u00b6 REST APIs \u00b6 We provide three types of methods: GET: Obtain data from the database; POST: Send/modify data to the database; DELETE: Delete data from the database. These three methods are available for the all the core objects in the graph database. Note that all following endpoints will be prefixed by /api/v1 so that this document is more concise. For example, the following endpoints are available for graphs: GET /graphs : obtain a list of graphs; GET /graphs/<graph_name> : obtain a particular graph; POST /graphs/<graph_name> : create a new graph in the database; DELETE /graphs/<graph_name> : delete an existing graph. The following endpoints are available for nodes: 1. GET /graphs/<graph_name>/nodes : obtain a list of nodes in a particular graph; 2. GET /graphs/<graph_name>/nodes/labels : obtain a list of nodes in a particular graph by labels; 3. GET /graphs/<graph_name>/nodes/<node_name> : get a particular node from a graph; 4. POST /graphs/<graph_name>/nodes/<node_name> : create a new node in the graph; 5. DELETE /graphs/<graph_name>/nodes/<node_name> : delete an existing node; 6. DELETE /graphs/<graph_name>/nodes : delete all nodes in the graph; 7. DELETE /graphs/<graph_name>/nodes/labels : delete all nodes in the graph by labels. The endpoints are available for relationships are similar. Each endpoint also allows specifying query parameters, e.g. GET /graphs/<graph_name>/?<query_params> . The returned object looks like the following: { \"version\": { \"api\": \"v2\", \"schema\": 0 }, \"exitCode\": 0, \"message\": \"successfully retrieved\", \"results\": [ { \"id\": \"0\", \"nodes\": [...] }, ... ] } OpenAPI Spec \u00b6 REST APIs can be generated via grpc-gateway . We can automatically generate OpenAPI spec as well. SDKs \u00b6 We also provide SDKs such as Python SDK to our users. First, initialize the client: client = tudb . Client ( address = xxx , config = xxx ) We can then get the graphs and nodes similar to REST APIs: // Get the list of graphs client . list_graphs () // Get a particular graph graph = client . get_graph ( name = xxx ) // Create a new graph graph = client . create_graph ( Graph ( ... )) // Delete a graph client . delete_graph ( name = xxx ) // Get the list of the nodes associated with the graph graph . list_nodes ( labels = xxx ) // Get a particular node graph . get_node ( name = xxx ) // Create a node graph . create_node ( Node ( ... )) // Delete a node graph . delete_node ( name = xxx ) // Get the list of relationships associated with the graph graph . list_relationships () // Get a particular relationship graph . get_relationship ( name = xxx ) // Create a relationship graph . create_relationship ( Relationship ( ... )) // Delete a relationship graph . delete_relationship ( name = xxx ) CLI \u00b6 Our CLI provides the following commands where object_type can be one of the following: graph, node, and relationship. tudb list <object_type> : get a list of objects of this type. tudb get <object_type> <object_name> : get a single object of this type. tudb create <object_type> -f <path_to_graph_definition> : create an object of this type based on the specified definition. tudb delete <object_type> <object_name> : delete a single object of this type. tudb delete <object_type> --all : delete all objects of this type. For nodes, there are also additional flags: 1. --labels : retrieving nodes that have this list of labels. For both nodes and relationships, we also need to provide --graph <graph_name> to associate with a graph when running the queries. Implementation Plan \u00b6 Some decisions after discussions: The current protobuf definition for core objects are unnecessarily complex and designed to support Gremlin in the future. However, we'd like to simplify the implementation of the service so that those definitions (e.g. Node and Relationship) are as close to the current storage API as possible. For example, Element and Property are unnecessary and can be removed for the initial implementation. We can revisit them later once we re-evaluate whether/how to support Gremlin. GraphService , NodeService , and RelationshipService focus on providing simple get/create/list methods that can be used for REST/CLI/Python clients. They will be implemented based on storage APIs. However, if users want to perform complex queries, the existing TuDBServer will be leveraged instead. The implementation plan for the Scala gRPC services consists of the following tasks: Add get/create/list methods in GraphService , NodeService , and RelationshipService that implement GraphServiceGrpc.GraphServiceImplBase (without integration with storage yet). Implement NodeService that uses NodeStoreAPI . For each node, we will include a graph_id in StoredNodeWithProperty 's properties so that later we can use it to look up nodes that belong to a graph in GraphService . Implement RelationshipService that uses RelationshipStoreAPI . Similarly, we will include a reference to the graph it belongs to in StoredRelationshipWithProperty 's properties. Implement GraphService that constructs a graph object with the list of nodes and relationships. Since the graph can get extremely large, we will support parameters like nodeCount and relationshipCount similar to Neo4j's graph.list() method to allow getting a subset of the nodes and relationships. The next phase of the development will be building the RESTful, CLI and Python interfaces based on the gRPC services implemented above. 1. RESTful APIs can be generated via grpc-gateway . We can automatically generate OpenAPI spec as well. 2. CLI will be built in Scala that invokes the gRPC services. 3. Python interface will be implemented in Python via gRPC calls to the running Scala gRPC services. References \u00b6 Gremlin structure APIs Neo4j Gremlin structure APIs TigerGraph REST APIs","title":"Protocol, Services, and Interfaces Design"},{"location":"protocol-services-interface-design/#protocol-services-and-interfaces-design","text":"","title":"Protocol, Services, and Interfaces Design"},{"location":"protocol-services-interface-design/#protocol-design","text":"","title":"Protocol Design"},{"location":"protocol-services-interface-design/#object-definitions","text":"Below are the main objects in the protocols. Our services are built on these objects. // Element is the basic structure for both Node and Relationship . It 's ID must be unique to its associated Node or Relationship. // An element also maintains a collection of Properties . An element must belong to a graph . message Element { int32 id = 1 ; string name = 2 ; // The graph ID associated with this element . int32 graph_id = 3 ; repeated Property properties = 4 ; } // Property holds a key - value pair that 's associated with an element. message Property { // The element ID associated with this property . int32 element_id = 1 ; string key = 2 ; google . protobuf . Any value = 3 ; } // Graph is a collection of nodes and relationships . message Graph { int32 id = 1 ; string name = 2 ; repeated Node nodes = 3 ; repeated Relationship relationships = 4 ; } // Node extends Element and connects to relationships . message Node { // The following fields are inherited from Element but we write them here explictly since proto3 does not support inheritance . int32 id = 1 string name = 2 ; int32 graph_id = 3 ; // The graph ID associated with this node . repeated Property properties = 4 ; repeated string labels = 5 ; Relationship in_relation = 6 ; Relationship out_relation = 7 ; } // Relationship extends Element and connects two nodes . message Relationship { // The following fields are inherited from Element but we write them here explictly since proto3 does not support inheritance . string id = 1 string name = 2 ; int32 graph_id = 3 ; // The graph ID associated with this relationship . repeated Property properties = 4 ; Node start_node = 5 ; Node end_node = 6 ; // The type of relationship between the two connected nodes . string relationType = 7 ; }","title":"Object Definitions"},{"location":"protocol-services-interface-design/#generic-query","text":"We support generic query for advanced users to send query directly to the database: The request only contains statement: message GenericQueryRequest { string statement = 1; } The response contains results (e.g. graph objects), message, and exit code: message GenericResponseStatus { string message = 2; int32 exit_code = 3; } message GenericQueryResponse { repeated map<string, google.protobuf.Any> results = 1; GenericResponseStatus status = 2; } The service definition is as follows: service QueryService { rpc Query(GenericQueryRequest) returns (stream GenericQueryResponse) {} }","title":"Generic Query"},{"location":"protocol-services-interface-design/#object-specific-services","text":"We support object-specific services such as create/get/delete graphs to provide easy-to-use endpoints to our REST client and high-level SDKs. Let's use graph service as an example: message GraphCreateRequest { Graph graph = 1 ; } ; message GraphCreateResponse { Graph graph = 1 ; GenericResponseStatus status = 2 ; } ; message GraphGetRequest { string name = 1 ; } ; message GraphGetResponse { Graph graph = 1 ; GenericResponseStatus status = 2 ; } ; message GraphListRequest { // TODO : Some filtering options } ; message GraphListResponse { repeated Graph graphs = 1 ; GenericResponseStatus status = 2 ; } ; message GraphDeleteRequest { string name = 1 ; } ; message GraphDeleteResponse { GenericResponseStatus status = 1 ; } ; service GraphService { rpc CreateGraph(GraphCreateRequest) returns GraphCreateResponse { option (google.api.http) = { post : \"/api/v1/graphs/{graph_name}\" body : \"*\" } ; } rpc GetGraph ( GraphGetRequest ) returns GraphGetResponse { option (google.api.http).get = \"/api/v1/graphs/{name } \"; } rpc ListGraphs(GraphListRequest) returns GraphListResponse { option (google.api.http).get = \" / api / v1 / graphs \"; } rpc DeleteGraph(GraphDeleteRequest) returns GraphDeleteResponse { option (google.api.http).get = \" / api / v1 / graphs / { name } \" ; } } Services for other objects are similar.","title":"Object-specific Services"},{"location":"protocol-services-interface-design/#interfaces","text":"","title":"Interfaces"},{"location":"protocol-services-interface-design/#rest-apis","text":"We provide three types of methods: GET: Obtain data from the database; POST: Send/modify data to the database; DELETE: Delete data from the database. These three methods are available for the all the core objects in the graph database. Note that all following endpoints will be prefixed by /api/v1 so that this document is more concise. For example, the following endpoints are available for graphs: GET /graphs : obtain a list of graphs; GET /graphs/<graph_name> : obtain a particular graph; POST /graphs/<graph_name> : create a new graph in the database; DELETE /graphs/<graph_name> : delete an existing graph. The following endpoints are available for nodes: 1. GET /graphs/<graph_name>/nodes : obtain a list of nodes in a particular graph; 2. GET /graphs/<graph_name>/nodes/labels : obtain a list of nodes in a particular graph by labels; 3. GET /graphs/<graph_name>/nodes/<node_name> : get a particular node from a graph; 4. POST /graphs/<graph_name>/nodes/<node_name> : create a new node in the graph; 5. DELETE /graphs/<graph_name>/nodes/<node_name> : delete an existing node; 6. DELETE /graphs/<graph_name>/nodes : delete all nodes in the graph; 7. DELETE /graphs/<graph_name>/nodes/labels : delete all nodes in the graph by labels. The endpoints are available for relationships are similar. Each endpoint also allows specifying query parameters, e.g. GET /graphs/<graph_name>/?<query_params> . The returned object looks like the following: { \"version\": { \"api\": \"v2\", \"schema\": 0 }, \"exitCode\": 0, \"message\": \"successfully retrieved\", \"results\": [ { \"id\": \"0\", \"nodes\": [...] }, ... ] }","title":"REST APIs"},{"location":"protocol-services-interface-design/#openapi-spec","text":"REST APIs can be generated via grpc-gateway . We can automatically generate OpenAPI spec as well.","title":"OpenAPI Spec"},{"location":"protocol-services-interface-design/#sdks","text":"We also provide SDKs such as Python SDK to our users. First, initialize the client: client = tudb . Client ( address = xxx , config = xxx ) We can then get the graphs and nodes similar to REST APIs: // Get the list of graphs client . list_graphs () // Get a particular graph graph = client . get_graph ( name = xxx ) // Create a new graph graph = client . create_graph ( Graph ( ... )) // Delete a graph client . delete_graph ( name = xxx ) // Get the list of the nodes associated with the graph graph . list_nodes ( labels = xxx ) // Get a particular node graph . get_node ( name = xxx ) // Create a node graph . create_node ( Node ( ... )) // Delete a node graph . delete_node ( name = xxx ) // Get the list of relationships associated with the graph graph . list_relationships () // Get a particular relationship graph . get_relationship ( name = xxx ) // Create a relationship graph . create_relationship ( Relationship ( ... )) // Delete a relationship graph . delete_relationship ( name = xxx )","title":"SDKs"},{"location":"protocol-services-interface-design/#cli","text":"Our CLI provides the following commands where object_type can be one of the following: graph, node, and relationship. tudb list <object_type> : get a list of objects of this type. tudb get <object_type> <object_name> : get a single object of this type. tudb create <object_type> -f <path_to_graph_definition> : create an object of this type based on the specified definition. tudb delete <object_type> <object_name> : delete a single object of this type. tudb delete <object_type> --all : delete all objects of this type. For nodes, there are also additional flags: 1. --labels : retrieving nodes that have this list of labels. For both nodes and relationships, we also need to provide --graph <graph_name> to associate with a graph when running the queries.","title":"CLI"},{"location":"protocol-services-interface-design/#implementation-plan","text":"Some decisions after discussions: The current protobuf definition for core objects are unnecessarily complex and designed to support Gremlin in the future. However, we'd like to simplify the implementation of the service so that those definitions (e.g. Node and Relationship) are as close to the current storage API as possible. For example, Element and Property are unnecessary and can be removed for the initial implementation. We can revisit them later once we re-evaluate whether/how to support Gremlin. GraphService , NodeService , and RelationshipService focus on providing simple get/create/list methods that can be used for REST/CLI/Python clients. They will be implemented based on storage APIs. However, if users want to perform complex queries, the existing TuDBServer will be leveraged instead. The implementation plan for the Scala gRPC services consists of the following tasks: Add get/create/list methods in GraphService , NodeService , and RelationshipService that implement GraphServiceGrpc.GraphServiceImplBase (without integration with storage yet). Implement NodeService that uses NodeStoreAPI . For each node, we will include a graph_id in StoredNodeWithProperty 's properties so that later we can use it to look up nodes that belong to a graph in GraphService . Implement RelationshipService that uses RelationshipStoreAPI . Similarly, we will include a reference to the graph it belongs to in StoredRelationshipWithProperty 's properties. Implement GraphService that constructs a graph object with the list of nodes and relationships. Since the graph can get extremely large, we will support parameters like nodeCount and relationshipCount similar to Neo4j's graph.list() method to allow getting a subset of the nodes and relationships. The next phase of the development will be building the RESTful, CLI and Python interfaces based on the gRPC services implemented above. 1. RESTful APIs can be generated via grpc-gateway . We can automatically generate OpenAPI spec as well. 2. CLI will be built in Scala that invokes the gRPC services. 3. Python interface will be implemented in Python via gRPC calls to the running Scala gRPC services.","title":"Implementation Plan"},{"location":"protocol-services-interface-design/#references","text":"Gremlin structure APIs Neo4j Gremlin structure APIs TigerGraph REST APIs","title":"References"},{"location":"roadmap/","text":"Roadmap \u00b6 TBA","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"TBA","title":"Roadmap"},{"location":"examples/basic/","text":"Basic Examples \u00b6 TBA","title":"Basic Examples"},{"location":"examples/basic/#basic-examples","text":"TBA","title":"Basic Examples"}]}